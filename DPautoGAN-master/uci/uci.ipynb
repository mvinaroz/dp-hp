{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, r2_score, explained_variance_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dp_wgan import Generator, Discriminator\n",
    "from dp_autoencoder import Autoencoder\n",
    "from evaluation import *\n",
    "import dp_optimizer, sampling, analysis, evaluation\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16276</td>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16277</td>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16278</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16279</td>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16280</td>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt   education  education-num  \\\n",
       "0       39          State-gov   77516   Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38            Private  215646     HS-grad              9   \n",
       "3       53            Private  234721        11th              7   \n",
       "4       28            Private  338409   Bachelors             13   \n",
       "...    ...                ...     ...         ...            ...   \n",
       "16276   39            Private  215419   Bachelors             13   \n",
       "16277   64                  ?  321403     HS-grad              9   \n",
       "16278   38            Private  374983   Bachelors             13   \n",
       "16279   44            Private   83891   Bachelors             13   \n",
       "16280   35       Self-emp-inc  182148   Bachelors             13   \n",
       "\n",
       "            marital-status          occupation     relationship  \\\n",
       "0            Never-married        Adm-clerical    Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial          Husband   \n",
       "2                 Divorced   Handlers-cleaners    Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners          Husband   \n",
       "4       Married-civ-spouse      Prof-specialty             Wife   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital-gain  capital-loss  \\\n",
       "0                    White     Male          2174             0   \n",
       "1                    White     Male             0             0   \n",
       "2                    White     Male             0             0   \n",
       "3                    Black     Male             0             0   \n",
       "4                    Black   Female             0             0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female             0             0   \n",
       "16277                Black     Male             0             0   \n",
       "16278                White     Male             0             0   \n",
       "16279   Asian-Pac-Islander     Male          5455             0   \n",
       "16280                White     Male             0             0   \n",
       "\n",
       "       hours-per-week  native-country  salary  \n",
       "0                  40   United-States   <=50K  \n",
       "1                  13   United-States   <=50K  \n",
       "2                  40   United-States   <=50K  \n",
       "3                  40   United-States   <=50K  \n",
       "4                  40            Cuba   <=50K  \n",
       "...               ...             ...     ...  \n",
       "16276              36   United-States   <=50K  \n",
       "16277              40   United-States   <=50K  \n",
       "16278              50   United-States   <=50K  \n",
       "16279              40   United-States   <=50K  \n",
       "16280              60   United-States    >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'salary']\n",
    "train = pd.read_csv('adult.data', names=names)\n",
    "test = pd.read_csv('adult.test', names=names)\n",
    "\n",
    "df = pd.concat([train, test])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self, datatypes):\n",
    "        self.datatypes = datatypes\n",
    "        \n",
    "    def fit(self, matrix):\n",
    "        preprocessors, cutoffs = [], []\n",
    "        for i, (column, datatype) in enumerate(self.datatypes):\n",
    "            preprocessed_col = matrix[:,i].reshape(-1, 1)\n",
    "\n",
    "            if 'categorical' in datatype:\n",
    "                preprocessor = LabelBinarizer()\n",
    "            else:\n",
    "                preprocessor = MinMaxScaler()\n",
    "\n",
    "            preprocessed_col = preprocessor.fit_transform(preprocessed_col)\n",
    "            cutoffs.append(preprocessed_col.shape[1])\n",
    "            preprocessors.append(preprocessor)\n",
    "        \n",
    "        self.cutoffs = cutoffs\n",
    "        self.preprocessors = preprocessors\n",
    "    \n",
    "    def transform(self, matrix):\n",
    "        preprocessed_cols = []\n",
    "        \n",
    "        for i, (column, datatype) in enumerate(self.datatypes):\n",
    "            preprocessed_col = matrix[:,i].reshape(-1, 1)\n",
    "            preprocessed_col = self.preprocessors[i].transform(preprocessed_col)\n",
    "            preprocessed_cols.append(preprocessed_col)\n",
    "\n",
    "        return np.concatenate(preprocessed_cols, axis=1)\n",
    "\n",
    "        \n",
    "    def fit_transform(self, matrix):\n",
    "        self.fit(matrix)\n",
    "        return self.transform(matrix)\n",
    "            \n",
    "    def inverse_transform(self, matrix):\n",
    "        postprocessed_cols = []\n",
    "\n",
    "        j = 0\n",
    "        for i, (column, datatype) in enumerate(self.datatypes):\n",
    "            postprocessed_col = self.preprocessors[i].inverse_transform(matrix[:,j:j+self.cutoffs[i]])\n",
    "\n",
    "            if 'categorical' in datatype:\n",
    "                postprocessed_col = postprocessed_col.reshape(-1, 1)\n",
    "            else:\n",
    "                if 'positive' in datatype:\n",
    "                    postprocessed_col = postprocessed_col.clip(min=0)\n",
    "\n",
    "                if 'int' in datatype:\n",
    "                    postprocessed_col = postprocessed_col.round()\n",
    "\n",
    "            postprocessed_cols.append(postprocessed_col)\n",
    "            \n",
    "            j += self.cutoffs[i]\n",
    "        \n",
    "        return np.concatenate(postprocessed_cols, axis=1)\n",
    "\n",
    "\n",
    "datatypes = [\n",
    "    ('age', 'positive int'),\n",
    "    ('workclass', 'categorical'),\n",
    "    ('education-num', 'categorical'),\n",
    "    ('marital-status', 'categorical'),\n",
    "    ('occupation', 'categorical'),\n",
    "    ('relationship', 'categorical'),\n",
    "    ('race', 'categorical'),\n",
    "    ('sex', 'categorical binary'),\n",
    "    ('capital-gain', 'positive float'),\n",
    "    ('capital-loss', 'positive float'),\n",
    "    ('hours-per-week', 'positive int'),\n",
    "    ('native-country', 'categorical'),\n",
    "    ('salary', 'categorical binary'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3014, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4521, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2877, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0685, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4795, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.1096, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0.2877, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.1507, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.3699, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.2877, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3699, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2466, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "processor = Processor(datatypes)\n",
    "\n",
    "relevant_df = df.drop(columns=['education', 'fnlwgt'])\n",
    "for column, datatype in datatypes:\n",
    "    if 'categorical' in datatype:\n",
    "        relevant_df[column] = relevant_df[column].astype('category').cat.codes\n",
    "        \n",
    "train_df = relevant_df.head(32562)\n",
    "\n",
    "X_real = torch.tensor(relevant_df.values.astype('float32'))\n",
    "X_encoded = torch.tensor(processor.fit_transform(X_real).astype('float32'))\n",
    "\n",
    "train_cutoff = 32562\n",
    "\n",
    "X_train_real = X_real[:train_cutoff]\n",
    "X_test_real = X_real[:train_cutoff]\n",
    "\n",
    "X_train_encoded = X_encoded[:train_cutoff]\n",
    "X_test_encoded = X_encoded[train_cutoff:]\n",
    "\n",
    "X_encoded.shape\n",
    "\n",
    "print(X_train_encoded)\n",
    "print(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_params = {\n",
    "    'b1': 0.9,\n",
    "    'b2': 0.999,\n",
    "    'binary': False,\n",
    "    'compress_dim': 15,\n",
    "    'delta': 1e-5,\n",
    "    'device': 'cuda',\n",
    "    'iterations': 20000,\n",
    "    'lr': 0.005,\n",
    "    'l2_penalty': 0.,\n",
    "    'l2_norm_clip': 0.012,\n",
    "    'minibatch_size': 64,\n",
    "    'microbatch_size': 1,\n",
    "    'noise_multiplier': 2.5,\n",
    "    'nonprivate': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(\n",
    "    example_dim=len(X_train_encoded[0]),\n",
    "    compression_dim=ae_params['compress_dim'],\n",
    "    binary=ae_params['binary'],\n",
    "    device=ae_params['device'],\n",
    ")\n",
    "\n",
    "decoder_optimizer = dp_optimizer.DPAdam(\n",
    "    l2_norm_clip=ae_params['l2_norm_clip'],\n",
    "    noise_multiplier=ae_params['noise_multiplier'],\n",
    "    minibatch_size=ae_params['minibatch_size'],\n",
    "    microbatch_size=ae_params['microbatch_size'],\n",
    "    nonprivate=ae_params['nonprivate'],\n",
    "    params=autoencoder.get_decoder().parameters(),\n",
    "    lr=ae_params['lr'],\n",
    "    betas=(ae_params['b1'], ae_params['b2']),\n",
    "    weight_decay=ae_params['l2_penalty'],\n",
    ")\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(\n",
    "    params=autoencoder.get_encoder().parameters(),\n",
    "    lr=ae_params['lr'] * ae_params['microbatch_size'] / ae_params['minibatch_size'],\n",
    "    betas=(ae_params['b1'], ae_params['b2']),\n",
    "    weight_decay=ae_params['l2_penalty'],\n",
    ")\n",
    "\n",
    "weights, ds = [], []\n",
    "for name, datatype in datatypes:\n",
    "    if 'categorical' in datatype:\n",
    "        num_values = len(np.unique(relevant_df[name]))\n",
    "        if num_values == 2:\n",
    "            weights.append(1.)\n",
    "            ds.append((datatype, 1))\n",
    "        else:\n",
    "            for i in range(num_values):\n",
    "                weights.append(1. / num_values)\n",
    "            ds.append((datatype, num_values))\n",
    "    else:\n",
    "        weights.append(1.)\n",
    "        ds.append((datatype, 1))\n",
    "weights = torch.tensor(weights).to(ae_params['device'])\n",
    "\n",
    "#autoencoder_loss = (lambda input, target: torch.mul(weights, torch.pow(input-target, 2)).sum(dim=1).mean(dim=0))\n",
    "#autoencoder_loss = lambda input, target: torch.mul(weights, F.binary_cross_entropy(input, target, reduction='none')).sum(dim=1).mean(dim=0)\n",
    "autoencoder_loss = nn.BCELoss()\n",
    "#autoencoder_loss = nn.MSELoss()\n",
    "\n",
    "print(autoencoder)\n",
    "\n",
    "print('Achieves ({}, {})-DP'.format(\n",
    "    analysis.epsilon(\n",
    "        len(X_train_encoded),\n",
    "        ae_params['minibatch_size'],\n",
    "        ae_params['noise_multiplier'],\n",
    "        ae_params['iterations'],\n",
    "        ae_params['delta']\n",
    "    ),\n",
    "    ae_params['delta'],\n",
    "))\n",
    "\n",
    "minibatch_loader, microbatch_loader = sampling.get_data_loaders(\n",
    "    minibatch_size=ae_params['minibatch_size'],\n",
    "    microbatch_size=ae_params['microbatch_size'],\n",
    "    iterations=ae_params['iterations'],\n",
    "    nonprivate=ae_params['nonprivate'],\n",
    ")\n",
    "\n",
    "train_losses, validation_losses = [], []\n",
    "\n",
    "X_train_encoded = X_train_encoded.to(ae_params['device'])\n",
    "X_test_encoded = X_test_encoded.to(ae_params['device'])\n",
    "\n",
    "for iteration, X_minibatch in enumerate(minibatch_loader(X_train_encoded)):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    for X_microbatch in microbatch_loader(X_minibatch):\n",
    "\n",
    "        decoder_optimizer.zero_microbatch_grad()\n",
    "        output = autoencoder(X_microbatch)\n",
    "        loss = autoencoder_loss(output, X_microbatch)\n",
    "        loss.backward()\n",
    "        decoder_optimizer.microbatch_step()\n",
    "        \n",
    "    validation_loss = autoencoder_loss(autoencoder(X_test_encoded).detach(), X_test_encoded)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "    validation_losses.append(validation_loss.item())\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "        print ('[Iteration %d/%d] [Loss: %f] [Validation Loss: %f]' % (\n",
    "            iteration, ae_params['iterations'], loss.item(), validation_loss.item())\n",
    "        )\n",
    "\n",
    "pd.DataFrame(data={'train': train_losses, 'validation': validation_losses}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ae_eps_inf.dat', 'wb') as f:\n",
    "    torch.save(autoencoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_params = {\n",
    "    'alpha': 0.99,\n",
    "    'binary': False,\n",
    "    'clip_value': 0.01,\n",
    "    'd_updates': 15,\n",
    "    'delta': 1e-5,\n",
    "    'device': 'cuda',\n",
    "    'iterations': 15000,\n",
    "    'latent_dim': 64,\n",
    "    'lr': 0.005,\n",
    "    'l2_penalty': 0.,\n",
    "    'l2_norm_clip': 0.022,\n",
    "    'minibatch_size': 128,\n",
    "    'microbatch_size': 1,\n",
    "    'noise_multiplier': 3.5,\n",
    "    'nonprivate': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('ae_eps_inf.dat', 'rb') as f:\n",
    "    autoencoder = torch.load(f)\n",
    "decoder = autoencoder.get_decoder()\n",
    "    \n",
    "generator = Generator(\n",
    "    input_dim=gan_params['latent_dim'],\n",
    "    output_dim=autoencoder.get_compression_dim(),\n",
    "    binary=gan_params['binary'],\n",
    "    device=gan_params['device'],\n",
    ")\n",
    "\n",
    "g_optimizer = torch.optim.RMSprop(\n",
    "    params=generator.parameters(),\n",
    "    lr=gan_params['lr'],\n",
    "    alpha=gan_params['alpha'],\n",
    "    weight_decay=gan_params['l2_penalty'],\n",
    ")\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    input_dim=len(X_train_encoded[0]),\n",
    "    device=gan_params['device'],\n",
    ")\n",
    "\n",
    "d_optimizer = dp_optimizer.DPRMSprop(\n",
    "    l2_norm_clip=gan_params['l2_norm_clip'],\n",
    "    noise_multiplier=gan_params['noise_multiplier'],\n",
    "    minibatch_size=gan_params['minibatch_size'],\n",
    "    microbatch_size=gan_params['microbatch_size'],\n",
    "    nonprivate=gan_params['nonprivate'],\n",
    "    params=discriminator.parameters(),\n",
    "    lr=gan_params['lr'],\n",
    "    alpha=gan_params['alpha'],\n",
    "    weight_decay=gan_params['l2_penalty'],\n",
    ")\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)\n",
    "\n",
    "print('Achieves ({}, {})-DP'.format(\n",
    "    analysis.epsilon(\n",
    "        len(X_train_encoded),\n",
    "        gan_params['minibatch_size'],\n",
    "        gan_params['noise_multiplier'],\n",
    "        gan_params['iterations'],\n",
    "        gan_params['delta']\n",
    "    ),\n",
    "    gan_params['delta'],\n",
    "))\n",
    "\n",
    "minibatch_loader, microbatch_loader = sampling.get_data_loaders(\n",
    "    minibatch_size=gan_params['minibatch_size'],\n",
    "    microbatch_size=gan_params['microbatch_size'],\n",
    "    iterations=gan_params['iterations'],\n",
    "    nonprivate=gan_params['nonprivate'],\n",
    ")\n",
    "\n",
    "X_train_encoded = X_train_encoded.to(gan_params['device'])\n",
    "X_test_encoded = X_test_encoded.to(ae_params['device'])\n",
    "\n",
    "for iteration, X_minibatch in enumerate(minibatch_loader(X_train_encoded)):\n",
    "    \n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    for real in microbatch_loader(X_minibatch):\n",
    "        z = torch.randn(real.size(0), gan_params['latent_dim'], device=gan_params['device'])\n",
    "        fake = decoder(generator(z)).detach()\n",
    "        \n",
    "        d_optimizer.zero_microbatch_grad()\n",
    "        d_loss = -torch.mean(discriminator(real)) + torch.mean(discriminator(fake))\n",
    "        d_loss.backward()\n",
    "        d_optimizer.microbatch_step()\n",
    "    \n",
    "    d_optimizer.step()\n",
    "\n",
    "    for parameter in discriminator.parameters():\n",
    "        parameter.data.clamp_(-gan_params['clip_value'], gan_params['clip_value'])\n",
    "\n",
    "    if iteration % gan_params['d_updates'] == 0:\n",
    "        z = torch.randn(X_minibatch.size(0), gan_params['latent_dim'], device=gan_params['device'])\n",
    "        fake = decoder(generator(z))\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss = -torch.mean(discriminator(fake))\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "        print('[Iteration %d/%d] [D loss: %f] [G loss: %f]' % (\n",
    "            iteration, gan_params['iterations'], d_loss.item(), g_loss.item()\n",
    "        ))\n",
    "        \n",
    "        z = torch.randn(len(X_train_real), gan_params['latent_dim'], device=gan_params['device'])\n",
    "        X_synthetic_encoded = decoder(generator(z)).cpu().detach().numpy()\n",
    "        X_synthetic_real = processor.inverse_transform(X_synthetic_encoded)\n",
    "        X_synthetic_encoded = processor.transform(X_synthetic_real)\n",
    "        synthetic_data = pd.DataFrame(X_synthetic_real, columns=relevant_df.columns)\n",
    "\n",
    "        i = 0\n",
    "        columns = relevant_df.columns\n",
    "        relevant_df[columns[i]].hist()\n",
    "        synthetic_data[columns[i]].hist()\n",
    "        plt.show()\n",
    "                \n",
    "        #pca_evaluation(pd.DataFrame(X_train_real), pd.DataFrame(X_synthetic_real))\n",
    "        #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_eps_inf.dat', 'wb') as f:\n",
    "    torch.save(generator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8449017199017199\n",
      "0.650905571685331\n"
     ]
    }
   ],
   "source": [
    "X_train_encoded = X_train_encoded.cpu()\n",
    "X_test_encoded = X_test_encoded.cpu()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_encoded[:,:-1], X_train_encoded[:,-1])\n",
    "prediction = clf.predict(X_test_encoded[:,:-1])\n",
    "\n",
    "print(accuracy_score(X_test_encoded[:,-1], prediction))\n",
    "print(f1_score(X_test_encoded[:,-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_eps_inf.dat', 'rb') as f:\n",
    "    generator = torch.load(f)\n",
    "    \n",
    "with open('ae_eps_inf.dat', 'rb') as f:\n",
    "    autoencoder = torch.load(f)\n",
    "decoder = autoencoder.get_decoder()\n",
    "\n",
    "z = torch.randn(len(X_train_real), gan_params['latent_dim'], device=gan_params['device'])\n",
    "X_synthetic_encoded = decoder(generator(z)).cpu().detach().numpy()\n",
    "X_synthetic_real = processor.inverse_transform(X_synthetic_encoded)\n",
    "X_synthetic_encoded = processor.transform(X_synthetic_real)\n",
    "\n",
    "#pd.DataFrame(X_encoded.numpy()).to_csv('real.csv')\n",
    "pd.DataFrame(X_synthetic_encoded).to_csv('synthetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7896191646191646\n",
      "0.28481937774065563\n"
     ]
    }
   ],
   "source": [
    "with open('gen_eps_inf.dat', 'rb') as f:\n",
    "    generator = torch.load(f)\n",
    "    \n",
    "with open('ae_eps_inf.dat', 'rb') as f:\n",
    "    autoencoder = torch.load(f)\n",
    "decoder = autoencoder.get_decoder()\n",
    "    \n",
    "X_test_encoded = X_test_encoded.cpu()\n",
    "\n",
    "z = torch.randn(len(X_train_real), gan_params['latent_dim'], device=gan_params['device'])\n",
    "X_synthetic_encoded = decoder(generator(z)).cpu().detach().numpy()\n",
    "\n",
    "X_synthetic_real = processor.inverse_transform(X_synthetic_encoded)\n",
    "X_synthetic_encoded = processor.transform(X_synthetic_real)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_synthetic_encoded[:,:-1], X_synthetic_encoded[:,-1])\n",
    "prediction = clf.predict(X_test_encoded[:,:-1])\n",
    "\n",
    "print(accuracy_score(X_test_encoded[:,-1], prediction))\n",
    "print(f1_score(X_test_encoded[:,-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gen_eps_inf.dat', 'rb') as f:\n",
    "    generator = torch.load(f)\n",
    "    \n",
    "with open('ae_eps_inf.dat', 'rb') as f:\n",
    "    autoencoder = torch.load(f)\n",
    "decoder = autoencoder.get_decoder()\n",
    "\n",
    "z = torch.randn(len(X_train_real), gan_params['latent_dim'], device=gan_params['device'])\n",
    "X_synthetic_encoded = decoder(generator(z)).cpu().detach().numpy()\n",
    "X_synthetic_real = processor.inverse_transform(X_synthetic_encoded)\n",
    "synthetic_data = pd.DataFrame(X_synthetic_real, columns=relevant_df.columns)\n",
    "\n",
    "column = 'age'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.hist(train_df[column].values,)# bins=)\n",
    "ax.hist(synthetic_data[column].values, color='red', alpha=0.35,)# bins10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age positive int\n",
      "r2_score\n",
      "Real: 0.2818276514546748\n",
      "Synthetic: 0.2934080317762404\n",
      "\n",
      "workclass categorical\n",
      "<lambda>\n",
      "Real: 0.7126535626535625\n",
      "Synthetic: 0.5954545454545455\n",
      "\n",
      "education-num categorical\n",
      "<lambda>\n",
      "Real: 0.3444103194103194\n",
      "Synthetic: 0.20356265356265357\n",
      "\n",
      "marital-status categorical\n",
      "<lambda>\n",
      "Real: 0.8179975429975429\n",
      "Synthetic: 0.6943488943488944\n",
      "\n",
      "occupation categorical\n",
      "<lambda>\n",
      "Real: 0.31713759213759213\n",
      "Synthetic: 0.10988943488943491\n",
      "\n",
      "relationship categorical\n",
      "<lambda>\n",
      "Real: 0.7573095823095823\n",
      "Synthetic: 0.6036240786240786\n",
      "\n",
      "race categorical\n",
      "<lambda>\n",
      "Real: 0.8418918918918918\n",
      "Synthetic: 0.6242014742014742\n",
      "\n",
      "sex categorical binary\n",
      "<lambda>\n",
      "Real: 0.8650217706821479\n",
      "Synthetic: 0.7528768254295888\n",
      "\n",
      "capital-gain positive float\n",
      "r2_score\n",
      "Real: 0.0842600819364091\n",
      "Synthetic: -0.45992054506116253\n",
      "\n",
      "capital-loss positive float\n",
      "r2_score\n",
      "Real: 0.025128599655994677\n",
      "Synthetic: -0.0388926609428184\n",
      "\n",
      "hours-per-week positive int\n",
      "r2_score\n",
      "Real: 0.03869403234808988\n",
      "Synthetic: 0.05981951744890357\n",
      "\n",
      "native-country categorical\n",
      "<lambda>\n",
      "Real: 0.8848280098280098\n",
      "Synthetic: 0.8514742014742015\n",
      "\n",
      "salary categorical binary\n",
      "<lambda>\n",
      "Real: 0.6341257560838373\n",
      "Synthetic: 0.23112078346028292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('gen_eps_inf.dat', 'rb') as f:\n",
    "    generator = torch.load(f)\n",
    "    \n",
    "with open('ae_eps_inf.dat', 'rb') as f:\n",
    "    autoencoder = torch.load(f)\n",
    "decoder = autoencoder.get_decoder()\n",
    "\n",
    "z = torch.randn(len(X_train_real), gan_params['latent_dim'], device=gan_params['device'])\n",
    "X_synthetic_encoded = decoder(generator(z)).cpu().detach().numpy()\n",
    "X_synthetic_real = processor.inverse_transform(X_synthetic_encoded)\n",
    "synthetic_data = pd.DataFrame(X_synthetic_real, columns=relevant_df.columns)\n",
    "\n",
    "regression_real = []\n",
    "classification_real = []\n",
    "regression_synthetic = []\n",
    "classification_synthetic = []\n",
    "target_real = []\n",
    "target_synthetic = []\n",
    "\n",
    "for column, datatype in datatypes:\n",
    "    p = Processor([datatype for datatype in datatypes if datatype[0] != column])\n",
    "    \n",
    "    train_cutoff = 32562\n",
    "    \n",
    "    p.fit(relevant_df.drop(columns=[column]).values)\n",
    "\n",
    "    X_enc = p.transform(relevant_df.drop(columns=[column]).values)\n",
    "    y_enc = relevant_df[column]\n",
    "\n",
    "    X_enc_train = X_enc[:train_cutoff]\n",
    "    X_enc_test = X_enc[train_cutoff:]\n",
    "    \n",
    "    y_enc_train = y_enc[:train_cutoff]\n",
    "    y_enc_test = y_enc[train_cutoff:]\n",
    "\n",
    "    X_enc_syn = p.transform(synthetic_data.drop(columns=[column]).values)\n",
    "    y_enc_syn = synthetic_data[column]\n",
    "        \n",
    "    if 'binary' in datatype:\n",
    "        model = lambda: RandomForestClassifier(n_estimators=10)\n",
    "        score = lambda true, pred: f1_score(true, pred)\n",
    "    elif 'categorical' in datatype:\n",
    "        model = lambda: RandomForestClassifier(n_estimators=10)\n",
    "        score = lambda true, pred: f1_score(true, pred, average='micro')\n",
    "    else:\n",
    "        model = lambda: Lasso()\n",
    "        explained_var = lambda true, pred: explained_variance_score(true, pred)\n",
    "        score = r2_score\n",
    "     \n",
    "    real, synthetic = model(), model()\n",
    "    \n",
    "    real.fit(X_enc_train, y_enc_train)\n",
    "    synthetic.fit(X_enc_syn, y_enc_syn)\n",
    "    \n",
    "    real_preds = real.predict(X_enc_test)\n",
    "    synthetic_preds = synthetic.predict(X_enc_test)\n",
    "    \n",
    "    print(column, datatype)\n",
    "    if column == 'salary':\n",
    "        target_real.append(score(y_enc_test, real_preds))\n",
    "        target_synthetic.append(score(y_enc_test, synthetic_preds))\n",
    "    elif 'categorical' in datatype:\n",
    "        classification_real.append(score(y_enc_test, real_preds))\n",
    "        classification_synthetic.append(score(y_enc_test, synthetic_preds))\n",
    "    else:\n",
    "        regression_real.append(score(y_enc_test, real_preds))\n",
    "        regression_synthetic.append(score(y_enc_test, synthetic_preds))\n",
    "\n",
    "    print(score.__name__)\n",
    "    print('Real: {}'.format(score(y_enc_test, real_preds)))\n",
    "    print('Synthetic: {}'.format(score(y_enc_test, synthetic_preds)))\n",
    "    print('')\n",
    "    \n",
    "plt.scatter(classification_real, classification_synthetic, c='blue')\n",
    "plt.scatter(regression_real, regression_synthetic, c='red')\n",
    "plt.scatter(target_real, target_synthetic, c='green')\n",
    "plt.xlabel('Real Data')\n",
    "plt.ylabel('Synthetic Data')\n",
    "plt.axis((0., 1., 0., 1.))\n",
    "plt.plot((0, 1), (0, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
